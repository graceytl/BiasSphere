{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d638065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Loaded configuration from .env file\n",
      "\n",
      "üîë API Key Status:\n",
      "  ‚úÖ Holistic AI Bedrock credentials loaded (will use Bedrock)\n",
      "  ‚úÖ Valyu API key loaded: Pcet7Qftke...\n",
      "\n",
      "üìÅ Working directory: /Users/zachmothner/UCL/BiasSphere/models\n",
      "\n",
      "‚úÖ Holistic AI Bedrock helper function loaded\n",
      "\n",
      "‚úÖ All imports successful!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ============================================\n",
    "#  oad from .env file (Recommended)\n",
    "# ============================================\n",
    "# Try to load from .env file in directory\n",
    "env_path = Path(\"./.env\")\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path)\n",
    "    print(\"üìÑ Loaded configuration from .env file\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No .env file found - using environment variables or hardcoded keys\")\n",
    "\n",
    "# ============================================\n",
    "# Verify API keys are set\n",
    "# ============================================\n",
    "print(\"\\nüîë API Key Status:\")\n",
    "if os.getenv(\"HOLISTIC_AI_TEAM_ID\") and os.getenv(\"HOLISTIC_AI_API_TOKEN\"):\n",
    "    print(\"  ‚úÖ Holistic AI Bedrock credentials loaded (will use Bedrock)\")\n",
    "elif os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"  ‚ö†Ô∏è  OpenAI API key loaded (Bedrock credentials not set)\")\n",
    "    print(\"     üí° Tip: Set HOLISTIC_AI_TEAM_ID and HOLISTIC_AI_API_TOKEN to use Bedrock (recommended)\")\n",
    "else:\n",
    "    print(\"  ‚ö†Ô∏è  No API keys found\")\n",
    "    print(\"     Set Holistic AI Bedrock credentials (recommended) or OpenAI key\")\n",
    "\n",
    "if os.getenv(\"VALYU_API_KEY\"):\n",
    "    key_preview = os.getenv(\"VALYU_API_KEY\")[:10] + \"...\"\n",
    "    print(f\"  ‚úÖ Valyu API key loaded: {key_preview}\")\n",
    "else:\n",
    "    print(\"  ‚ö†Ô∏è  Valyu API key not found - search tool will not work\")\n",
    "\n",
    "print(\"\\nüìÅ Working directory:\", Path.cwd())\n",
    "\n",
    "# ============================================\n",
    "# Import Holistic AI Bedrock helper function\n",
    "# ============================================\n",
    "# Import from core module (recommended)\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    sys.path.insert(0, \"./core\")\n",
    "    from react_agent.holistic_ai_bedrock import HolisticAIBedrockChat, get_chat_model\n",
    "\n",
    "    print(\"\\n‚úÖ Holistic AI Bedrock helper function loaded\")\n",
    "except ImportError:\n",
    "    print(\"\\n‚ö†Ô∏è  Could not import from core - will use OpenAI only\")\n",
    "    print(\"   Make sure core/react_agent/holistic_ai_bedrock.py exists\")\n",
    "\n",
    "# Import official packages\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "print(\"\\n‚úÖ All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6b9d403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Testing Valyu Search Tool Directly\n",
      "======================================================================\n",
      "Query: latest developments in quantum computing\n",
      "\n",
      "üìÑ Search Results (first 500 chars):\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"success\": true,\n",
      "  \"error\": \"\",\n",
      "  \"tx_id\": \"tx_70d2997c-b9f8-4bc9-bdcc-22624f415a14\",\n",
      "  \"query\": \"latest developments in quantum computing\",\n",
      "  \"results\": [\n",
      "    {\n",
      "      \"title\": \"News - Quantum Computing Report\",\n",
      "      \"url\": \"https://quantumcomputingreport.com/news/?utm_source=valyu.ai&utm_medium=referral\",\n",
      "      \"content\": \"# News\\n\\nRecent news items published within the last 6 months on quantum computing developments are listed below. Click on the hyperlinked item to go to the press relea...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üìä Total data returned: 94655 characters\n",
      "‚úÖ This data will be passed to the agent to answer questions!\n"
     ]
    }
   ],
   "source": [
    "# import time\n",
    "# from langgraph.prebuilt import create_react_agent\n",
    "# from langchain_core.messages import HumanMessage\n",
    "\n",
    "# # Example 2: ReAct Agent (no tools yet)\n",
    "# print(\"=\"*70)\n",
    "# print(\"EXAMPLE 2: ReAct Agent (No Tools)\")\n",
    "# print(\"=\"*70)\n",
    "\n",
    "# # Create LLM using helper function\n",
    "# llm = get_chat_model(\"claude-3-5-sonnet\")\n",
    "\n",
    "# # Create ReAct agent with NO tools (for now)\n",
    "# agent = create_react_agent(llm, tools=[])\n",
    "\n",
    "# # Use the same question from Example 1\n",
    "# question = \"What is quantum computing?\"\n",
    "# print(f\"\\n‚ùì Same Question: {question}\")\n",
    "\n",
    "# start_time = time.time()\n",
    "# result = agent.invoke({\"messages\": [HumanMessage(content=question)]})\n",
    "# elapsed = time.time() - start_time\n",
    "\n",
    "# print(f\"\\nüí¨ Response: {result['messages'][-1].content}\")\n",
    "# print(f\"\\n‚è±Ô∏è  Time: {elapsed:.2f}s\")\n",
    "# print(f\"üìä Messages in conversation: {len(result['messages'])}\")\n",
    "# print(\"\\n‚úÖ Agent can maintain context, use tools (when provided), and handle multi-turn!\")\n",
    "\n",
    "# Import official Valyu tool from langchain-valyu package\n",
    "from langchain_valyu import ValyuSearchTool\n",
    "\n",
    "# Create search tool with configuration\n",
    "search_tool = ValyuSearchTool(\n",
    "    valyu_api_key=os.getenv(\"VALYU_API_KEY\"),\n",
    "    # Optional: configure search parameters (can also be set per-call)\n",
    "    # search_type=\"all\",  # Search both proprietary and web sources\n",
    "    # max_num_results=5,   # Limit results\n",
    "    # relevance_threshold=0.5,  # Minimum relevance score\n",
    "    # max_price=20.0  # Maximum cost in dollars\n",
    ")\n",
    "\n",
    "# Test it directly\n",
    "print(\"üîç Testing Valyu Search Tool Directly\")\n",
    "print(\"=\" * 70)\n",
    "test_query = \"latest developments in quantum computing\"\n",
    "print(f\"Query: {test_query}\\n\")\n",
    "\n",
    "# Call the search tool\n",
    "search_results = search_tool._run(query=test_query, search_type=\"all\", max_num_results=5)\n",
    "\n",
    "# Display results (truncated for readability)\n",
    "result_str = str(search_results)\n",
    "print(\"üìÑ Search Results (first 500 chars):\")\n",
    "print(\"-\" * 70)\n",
    "print(result_str[:500] + \"...\" if len(result_str) > 500 else result_str)\n",
    "print(\"-\" * 70)\n",
    "print(f\"\\nüìä Total data returned: {len(result_str)} characters\")\n",
    "print(\"‚úÖ This data will be passed to the agent to answer questions!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "051183fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TEST 2: Agent WITH Search\n",
      "======================================================================\n",
      "\n",
      "‚ùì Same Question: What are the latest breakthroughs in quantum computing in 2025?\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gt/r39m3yss08l05rhcqrtkyys40000gn/T/ipykernel_1581/3187584785.py:30: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
      "  agent_with_search = create_react_agent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí¨ Response (WITH search):\n",
      "----------------------------------------------------------------------\n",
      "Based on the search results, I can provide a summary of the key quantum computing breakthroughs and developments in 2024-2025:\n",
      "\n",
      "Key Breakthroughs:\n",
      "\n",
      "1. Google's Willow Chip (Late 2024):\n",
      "- Achieved significant improvement in error correction and noise reduction\n",
      "- Demonstrated ability to perform computations that would take classical supercomputers extremely long periods to solve\n",
      "- Represents progress toward threshold scalability, though still not ready for practical applications\n",
      "\n",
      "2. Microsoft's Developments:\n",
      "- Unveiled the world's first quantum processor powered by topological qubits\n",
      "- Integrate...\n",
      "----------------------------------------------------------------------\n",
      "‚è±Ô∏è  Time: 55.61s\n",
      "\n",
      "‚úÖ Note: Real-time data, specific sources, up-to-date information!\n"
     ]
    }
   ],
   "source": [
    "# Test question about recent events (requires current information)\n",
    "recent_question = \"What are the latest breakthroughs in quantum computing in 2025?\"\n",
    "\n",
    "# print(\"=\"*70)\n",
    "# print(\"TEST 1: Agent WITHOUT Search\")\n",
    "# print(\"=\"*70)\n",
    "# print(f\"‚ùì Question: {recent_question}\\n\")\n",
    "\n",
    "# start_time = time.time()\n",
    "# result_no_search = agent.invoke({\n",
    "#     \"messages\": [HumanMessage(content=recent_question)]\n",
    "# })\n",
    "# elapsed_no_search = time.time() - start_time\n",
    "\n",
    "# print(\"üí¨ Response (NO search):\")\n",
    "# print(\"-\"*70)\n",
    "# response_text = result_no_search['messages'][-1].content\n",
    "# print(response_text[:400] + \"...\" if len(response_text) > 400 else response_text)\n",
    "# print(\"-\"*70)\n",
    "# print(f\"‚è±Ô∏è  Time: {elapsed_no_search:.2f}s\")\n",
    "# print(f\"\\n‚ö†Ô∏è  Note: Generic answer, likely outdated or vague (LLM training data cutoff)\")\n",
    "\n",
    "# Now create agent WITH search tool\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TEST 2: Agent WITH Search\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create new agent with Valyu search tool (uses Holistic AI Bedrock by default)\n",
    "llm_with_tools = get_chat_model(\"claude-3-5-sonnet\")\n",
    "agent_with_search = create_react_agent(\n",
    "    llm_with_tools,\n",
    "    tools=[search_tool],  # Add the search tool!\n",
    ")\n",
    "\n",
    "print(f\"\\n‚ùì Same Question: {recent_question}\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "result_with_search = agent_with_search.invoke({\"messages\": [HumanMessage(content=recent_question)]})\n",
    "elapsed_with_search = time.time() - start_time\n",
    "\n",
    "print(\"üí¨ Response (WITH search):\")\n",
    "print(\"-\" * 70)\n",
    "response_text = result_with_search[\"messages\"][-1].content\n",
    "print(response_text[:600] + \"...\" if len(response_text) > 600 else response_text)\n",
    "print(\"-\" * 70)\n",
    "print(f\"‚è±Ô∏è  Time: {elapsed_with_search:.2f}s\")\n",
    "print(\"\\n‚úÖ Note: Real-time data, specific sources, up-to-date information!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "506c143a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Message Trace (WITH search):\n",
      "======================================================================\n",
      "\n",
      "1. HumanMessage\n",
      "----------------------------------------------------------------------\n",
      "   User: What are the latest breakthroughs in quantum computing in 2025?...\n",
      "\n",
      "2. AIMessage\n",
      "----------------------------------------------------------------------\n",
      "   AI decided to call tool: valyu_deep_search\n",
      "   Args: {'query': 'major breakthroughs developments quantum computing 2025', 'start_date': '2025-01-01', 'end_date': '2025-12-31', 'max_num_results': 10}\n",
      "\n",
      "3. ToolMessage\n",
      "----------------------------------------------------------------------\n",
      "   Tool returned: {\n",
      "  \"success\": false,\n",
      "  \"error\": \"HTTP Error: 504\",\n",
      "  \"tx_id\": \"error-504\",\n",
      "  \"query\": \"major breakt...\n",
      "\n",
      "4. AIMessage\n",
      "----------------------------------------------------------------------\n",
      "   AI decided to call tool: valyu_deep_search\n",
      "   Args: {'query': 'latest breakthroughs developments quantum computing 2024', 'max_num_results': 10}\n",
      "\n",
      "5. ToolMessage\n",
      "----------------------------------------------------------------------\n",
      "   Tool returned: {\n",
      "  \"success\": true,\n",
      "  \"error\": \"\",\n",
      "  \"tx_id\": \"tx_4ad7df01-9c40-4370-9939-f2b6b5f50cc7\",\n",
      "  \"query\":...\n",
      "\n",
      "6. AIMessage\n",
      "----------------------------------------------------------------------\n",
      "   AI response: Based on the search results, I can provide a summary of the key quantum computing breakthroughs and developments in 2024-2025:\n",
      "\n",
      "Key Breakthroughs:\n",
      "\n",
      "1....\n",
      "\n",
      "======================================================================\n",
      "Total messages: 6\n",
      "\n",
      "This shows the complete ReAct loop: User ‚Üí AI (tool call) ‚Üí Tool ‚Üí AI (answer)\n"
     ]
    }
   ],
   "source": [
    "print(\"üìä Message Trace (WITH search):\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, msg in enumerate(result_with_search[\"messages\"]):\n",
    "    msg_type = type(msg).__name__\n",
    "    print(f\"\\n{i + 1}. {msg_type}\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "    if msg_type == \"HumanMessage\":\n",
    "        print(f\"   User: {msg.content[:100]}...\")\n",
    "\n",
    "    elif msg_type == \"AIMessage\":\n",
    "        if hasattr(msg, \"tool_calls\") and msg.tool_calls:\n",
    "            print(f\"   AI decided to call tool: {msg.tool_calls[0]['name']}\")\n",
    "            print(f\"   Args: {msg.tool_calls[0]['args']}\")\n",
    "        else:\n",
    "            content_preview = msg.content[:150] + \"...\" if len(msg.content) > 150 else msg.content\n",
    "            print(f\"   AI response: {content_preview}\")\n",
    "\n",
    "    elif msg_type == \"ToolMessage\":\n",
    "        content_preview = msg.content[:100] + \"...\" if len(msg.content) > 100 else msg.content\n",
    "        print(f\"   Tool returned: {content_preview}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"Total messages: {len(result_with_search['messages'])}\")\n",
    "print(\"\\nThis shows the complete ReAct loop: User ‚Üí AI (tool call) ‚Üí Tool ‚Üí AI (answer)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ede93dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema defined!\n",
      "   Fields: ['entities']\n",
      "   Entity Fields: ['name', 'tone', 'evidence_sentences', 'loaded_phrases']\n",
      "   Validation: Built-in with Pydantic\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "\n",
    "# Define output schema\n",
    "class Entity(BaseModel):\n",
    "    \"\"\"Person, group, or institution mentioned in the article. Contains information and evidence about bias presented.\"\"\"\n",
    "\n",
    "    name: str = Field(description=\"Name of person, group, institution, or organization mentioned\")\n",
    "    tone: str = Field(\n",
    "        description=\"Sentiment within the article towards the entity mentioned: MUST be one of the following: 'very positive', 'positive', 'neutral', 'negative', 'very negative'\"\n",
    "    )\n",
    "    evidence_sentences: List[str] = Field(\n",
    "        description=\"Phrases or sentences pulled directly from the provided article that demonstrate the sentiment of the article toward this entity\"\n",
    "    )\n",
    "    loaded_phrases: List[str] = Field(\n",
    "        description=\"Emotionally charged or manipulative wording or phrases used in the article pertaining to the entity\"\n",
    "    )\n",
    "\n",
    "\n",
    "class EntityAnalysis(BaseModel):\n",
    "    \"\"\"Analysis of the entities discussed in the article and how the sentiment presented toward them.\"\"\"\n",
    "\n",
    "    entities: List[Entity] = Field(description=\"All of the people, groups, or institutions mentioned in the article.\")\n",
    "\n",
    "\n",
    "print(\"Schema defined!\")\n",
    "print(f\"   Fields: {list(EntityAnalysis.model_fields.keys())}\")\n",
    "print(f\"   Entity Fields: {list(Entity.model_fields.keys())}\")\n",
    "print(\"   Validation: Built-in with Pydantic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0b6eca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LLM with structured output created!\n",
      "   Model: claude-3-5-sonnet (via Bedrock)\n",
      "   Output format: TechAnalysis (JSON)\n",
      "   Validation: Automatic with Pydantic\n"
     ]
    }
   ],
   "source": [
    "# Create base LLM\n",
    "# Use get_chat_model() - uses Holistic AI Bedrock by default (recommended)\n",
    "llm = get_chat_model(\"claude-3-5-sonnet\")  # Uses Holistic AI Bedrock (recommended)\n",
    "\n",
    "# Create LLM with structured output\n",
    "llm_structured = llm.with_structured_output(EntityAnalysis)\n",
    "print(\"‚úÖ LLM with structured output created!\")\n",
    "print(\"   Model: claude-3-5-sonnet (via Bedrock)\")\n",
    "print(\"   Output format: TechAnalysis (JSON)\")\n",
    "print(\"   Validation: Automatic with Pydantic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e3020cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: You are an entity-level bias detector.\n",
      "\n",
      "Identify all people, groups, or institutions discussed in the article.\n",
      "For each entity, determine the tone:\n",
      "'very_positive', 'positive', 'neutral', 'negative', 'very_negative'\n",
      "\n",
      "Extract:\n",
      "- 1‚Äì3 evidence sentences that reflect this tone\n",
      "- any \"loaded phrases\" (emotionally charged or manipulative wording)\n",
      "\n",
      "Article:\n",
      "\"More than 300 people gathered in Bournemouth earlier as a planned immigration protest took place.\n",
      "The march, organised by Bournemouth Patriots, with a \"stop the boats\" message, followed a pre-agreed route along Meyrick Road to a designated location near the Lansdowne.\n",
      "\n",
      "Counter protesters and supporters of Stand up to Racism were also present, with many chanting \"refugees are welcome here\".\n",
      "\n",
      "Dorset Police said it respected people's right to peaceful protest, but were \"imposing conditions for safety\" and to \"minimise disruption\".\n",
      "\n",
      "BBC reporter Steve Humphrey said about 300 people gathered at the height of the protest, with equal numbers from both sides.\n",
      "\n",
      "He said some were chanting, while waving Union Jack and England flags.\n",
      "\n",
      "It was the latest in a series of protests in the town, with police warning demonstrators would be committing an offence if they failed to follow official instructions.\n",
      "\n",
      "The Bournemouth Patriots turned down an invitation to be interviewed by the BBC and said the corporation was not welcome at the event.\"\n",
      "\n",
      "======================================================================\n",
      "Structured Output (Pydantic Object):\n",
      "======================================================================\n",
      "  1. name='Bournemouth Patriots' tone='negative' evidence_sentences=[\"The march, organised by Bournemouth Patriots, with a 'stop the boats' message, followed a pre-agreed route along Meyrick Road\", 'The Bournemouth Patriots turned down an invitation to be interviewed by the BBC and said the corporation was not welcome at the event'] loaded_phrases=['stop the boats']\n",
      "  2. name='Stand up to Racism' tone='positive' evidence_sentences=[\"Counter protesters and supporters of Stand up to Racism were also present, with many chanting 'refugees are welcome here'\"] loaded_phrases=['refugees are welcome here']\n",
      "  3. name='Dorset Police' tone='neutral' evidence_sentences=[\"Dorset Police said it respected people's right to peaceful protest, but were 'imposing conditions for safety' and to 'minimise disruption'\", 'It was the latest in a series of protests in the town, with police warning demonstrators would be committing an offence if they failed to follow official instructions'] loaded_phrases=[]\n",
      "  4. name='BBC' tone='neutral' evidence_sentences=['BBC reporter Steve Humphrey said about 300 people gathered at the height of the protest, with equal numbers from both sides', 'The Bournemouth Patriots turned down an invitation to be interviewed by the BBC and said the corporation was not welcome at the event'] loaded_phrases=[]\n",
      "  5. name='Steve Humphrey' tone='neutral' evidence_sentences=['BBC reporter Steve Humphrey said about 300 people gathered at the height of the protest, with equal numbers from both sides'] loaded_phrases=[]\n",
      "======================================================================\n",
      "Time: 8.22s\n"
     ]
    }
   ],
   "source": [
    "# Test structured output\n",
    "question = 'You are an entity-level bias detector.\\n\\nIdentify all people, groups, or institutions discussed in the article.\\nFor each entity, determine the tone:\\n\\'very_positive\\', \\'positive\\', \\'neutral\\', \\'negative\\', \\'very_negative\\'\\n\\nExtract:\\n- 1‚Äì3 evidence sentences that reflect this tone\\n- any \"loaded phrases\" (emotionally charged or manipulative wording)\\n\\nArticle:\\n\"More than 300 people gathered in Bournemouth earlier as a planned immigration protest took place.\\nThe march, organised by Bournemouth Patriots, with a \"stop the boats\" message, followed a pre-agreed route along Meyrick Road to a designated location near the Lansdowne.\\n\\nCounter protesters and supporters of Stand up to Racism were also present, with many chanting \"refugees are welcome here\".\\n\\nDorset Police said it respected people\\'s right to peaceful protest, but were \"imposing conditions for safety\" and to \"minimise disruption\".\\n\\nBBC reporter Steve Humphrey said about 300 people gathered at the height of the protest, with equal numbers from both sides.\\n\\nHe said some were chanting, while waving Union Jack and England flags.\\n\\nIt was the latest in a series of protests in the town, with police warning demonstrators would be committing an offence if they failed to follow official instructions.\\n\\nThe Bournemouth Patriots turned down an invitation to be interviewed by the BBC and said the corporation was not welcome at the event.\"'\n",
    "\n",
    "# question = \"You are an entity-level bias detector.\\n\\nIdentify all people, groups, or institutions discussed in the article.\\nFor each entity, determine the tone:\\n'very_positive', 'positive', 'neutral', 'negative', 'very_negative'\\n\\nExtract:\\n- 1‚Äì3 evidence sentences that reflect this tone\\n- any \\\"loaded phrases\\\" (emotionally charged or manipulative wording)\\n\\nArticle:\\n\\\"The Strategic Uncoupling of Zohran Mamdani and Brad Lander\\n\\nMr. Lander, the New York City comptroller, campaigned with Mr. Mamdani and once hoped to join him in City Hall. Now he is eyeing a congressional seat. Zohran Mamdani was in the final, chaotic sprint to Election Day in the New York City mayor‚Äôs race, when he stepped off the campaign trail for an important meeting.\\n\\nSitting with him was Brad Lander, the city comptroller who had become one of his closest allies. Their \\‚Äúprogressive bromance\\‚Äù during the Democratic primary in June had helped cinch Mr. Mamdani\\‚Äôs victory and left Mr. Lander gunning for City Hall, too, hopefully as his top deputy.\\n\\nBut when they met on a chaotic Sunday in late October, amid church services and canvass launches, Mr. Mamdani, a state assemblyman, wanted to talk about a different idea that Mr. Lander had floated. He told the comptroller that he would like to continue their partnership ‚Äî by supporting him in a primary challenge against Representative Daniel Goldman, a vulnerable and more moderate Democrat, according to three people familiar with the exchange.\\n\\nAs for the high-level administration post Mr. Lander, 56, had also coveted, Mr. Mamdani told him that he planned to go in a different direction.The sharp change-up has captivated New York‚Äôs political chattering class since it spilled into public in recent days, setting the stage for a potentially explosive House primary in the heart of New York City.\\n\\nMr. Mamdani\\‚Äôs quiet maneuvering ‚Äî much of which has not been previously reported ‚Äî has also offered an early window into the unsentimental calculations guiding the incoming mayor as he builds his administration and flexes his political muscle.\\n\\nAsked to comment for this story, Mr. Mamdani‚Äôs spokeswoman, Dora Pekec, said simply that Mr. Lander ‚Äúcontinues to be a trusted ally and partner to the mayor-elect.‚Äù But other supporters who have spoken to him added that Mr. Mamdani, a sharp critic of Israel, was eager to unseat Mr. Goldman, whose views on the war in Gaza and other issues are well to his right.\\n\\nPeople who have spoken with Mr. Lander recently said he had played down the sting of being passed over for a top city post.\\n\\n\\‚ÄúBrad\\‚Äôs moral clarity, his willingness to use his voice to defend our democracy and put his body on the line to protect our neighbors are all vitally important and unfortunately all too rare,‚Äù said his top adviser, Alison Hirsh. She said he would bring these qualities to Washington ‚Äúif he chooses to run.‚Äù\\n\\nThe relationship between Mr. Lander and Mr. Mamdani has been the subject of unusual interest since the two men rolled out a novel cross-endorsement in June as competing candidates for mayor. Politicians often talk about forming alliances to defeat a common enemy, in this case former Gov. Andrew M. Cuomo, but rarely follow through.Mr. Lander, a well-known progressive with 15 years in public office, vouched for Mr. Mamdani, a 34-year-old Muslim and democratic socialist, with fellow Jewish Democrats. And after federal agents arrested Mr. Lander as he escorted migrants in an immigration courthouse, he used some of the attention to boost his formal rival.\\n\\nOn the night of his primary victory, Mr. Mamdani put his arm around Mr. Lander and said they had modeled \\‚Äúthe politics of the future, one of partnership and of sincerity.\\‚Äù\\n\\nMany progressive New Yorkers supporting Mr. Mamdani ‚Äî but uncertain about his youth with just five years in the State Assembly under his belt ‚Äî felt comforted by the prospect of Mr. Lander joining City Hall as a partner overseeing the city‚Äôs day-to-day operations.\\\"\"\n",
    "\n",
    "print(f\"Question: {question}\\n\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "start_time = time.time()\n",
    "result = llm_structured.invoke(question)\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(\"Structured Output (Pydantic Object):\")\n",
    "print(\"=\" * 70)\n",
    "for i, entity in enumerate(result.entities, 1):\n",
    "    print(f\"  {i}. {entity}\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"Time: {elapsed:.2f}s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biassphere",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
