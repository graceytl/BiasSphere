{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d638065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Loaded configuration from .env file\n",
      "\n",
      "üîë API Key Status:\n",
      "  ‚úÖ Holistic AI Bedrock credentials loaded (will use Bedrock)\n",
      "  ‚úÖ Valyu API key loaded: Pcet7Qftke...\n",
      "\n",
      "üìÅ Working directory: /Users/wietske/Documents/UCL2025/Misc/BiasSphere/models\n",
      "\n",
      "‚úÖ Holistic AI Bedrock helper function loaded\n",
      "\n",
      "‚úÖ All imports successful!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ============================================\n",
    "#  oad from .env file (Recommended)\n",
    "# ============================================\n",
    "# Try to load from .env file in directory\n",
    "env_path = Path(\"./.env\")\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path)\n",
    "    print(\"üìÑ Loaded configuration from .env file\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No .env file found - using environment variables or hardcoded keys\")\n",
    "\n",
    "# ============================================\n",
    "# Verify API keys are set\n",
    "# ============================================\n",
    "print(\"\\nüîë API Key Status:\")\n",
    "if os.getenv(\"HOLISTIC_AI_TEAM_ID\") and os.getenv(\"HOLISTIC_AI_API_TOKEN\"):\n",
    "    print(\"  ‚úÖ Holistic AI Bedrock credentials loaded (will use Bedrock)\")\n",
    "elif os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"  ‚ö†Ô∏è  OpenAI API key loaded (Bedrock credentials not set)\")\n",
    "    print(\"     üí° Tip: Set HOLISTIC_AI_TEAM_ID and HOLISTIC_AI_API_TOKEN to use Bedrock (recommended)\")\n",
    "else:\n",
    "    print(\"  ‚ö†Ô∏è  No API keys found\")\n",
    "    print(\"     Set Holistic AI Bedrock credentials (recommended) or OpenAI key\")\n",
    "\n",
    "if os.getenv(\"VALYU_API_KEY\"):\n",
    "    key_preview = os.getenv(\"VALYU_API_KEY\")[:10] + \"...\"\n",
    "    print(f\"  ‚úÖ Valyu API key loaded: {key_preview}\")\n",
    "else:\n",
    "    print(\"  ‚ö†Ô∏è  Valyu API key not found - search tool will not work\")\n",
    "\n",
    "print(\"\\nüìÅ Working directory:\", Path.cwd())\n",
    "\n",
    "# ============================================\n",
    "# Import Holistic AI Bedrock helper function\n",
    "# ============================================\n",
    "# Import from core module (recommended)\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    sys.path.insert(0, \"./core\")\n",
    "    from react_agent.holistic_ai_bedrock import HolisticAIBedrockChat, get_chat_model\n",
    "\n",
    "    print(\"\\n‚úÖ Holistic AI Bedrock helper function loaded\")\n",
    "except ImportError:\n",
    "    print(\"\\n‚ö†Ô∏è  Could not import from core - will use OpenAI only\")\n",
    "    print(\"   Make sure core/react_agent/holistic_ai_bedrock.py exists\")\n",
    "\n",
    "# Import official packages\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "print(\"\\n‚úÖ All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6b9d403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Testing Valyu Search Tool Directly\n",
      "======================================================================\n",
      "Query: latest developments in quantum computing\n",
      "\n",
      "üìÑ Search Results (first 500 chars):\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "  \"success\": true,\n",
      "  \"error\": \"\",\n",
      "  \"tx_id\": \"tx_70d2997c-b9f8-4bc9-bdcc-22624f415a14\",\n",
      "  \"query\": \"latest developments in quantum computing\",\n",
      "  \"results\": [\n",
      "    {\n",
      "      \"title\": \"News - Quantum Computing Report\",\n",
      "      \"url\": \"https://quantumcomputingreport.com/news/?utm_source=valyu.ai&utm_medium=referral\",\n",
      "      \"content\": \"# News\\n\\nRecent news items published within the last 6 months on quantum computing developments are listed below. Click on the hyperlinked item to go to the press relea...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üìä Total data returned: 94655 characters\n",
      "‚úÖ This data will be passed to the agent to answer questions!\n"
     ]
    }
   ],
   "source": [
    "# import time\n",
    "# from langgraph.prebuilt import create_react_agent\n",
    "# from langchain_core.messages import HumanMessage\n",
    "\n",
    "# # Example 2: ReAct Agent (no tools yet)\n",
    "# print(\"=\"*70)\n",
    "# print(\"EXAMPLE 2: ReAct Agent (No Tools)\")\n",
    "# print(\"=\"*70)\n",
    "\n",
    "# # Create LLM using helper function\n",
    "# llm = get_chat_model(\"claude-3-5-sonnet\")\n",
    "\n",
    "# # Create ReAct agent with NO tools (for now)\n",
    "# agent = create_react_agent(llm, tools=[])\n",
    "\n",
    "# # Use the same question from Example 1\n",
    "# question = \"What is quantum computing?\"\n",
    "# print(f\"\\n‚ùì Same Question: {question}\")\n",
    "\n",
    "# start_time = time.time()\n",
    "# result = agent.invoke({\"messages\": [HumanMessage(content=question)]})\n",
    "# elapsed = time.time() - start_time\n",
    "\n",
    "# print(f\"\\nüí¨ Response: {result['messages'][-1].content}\")\n",
    "# print(f\"\\n‚è±Ô∏è  Time: {elapsed:.2f}s\")\n",
    "# print(f\"üìä Messages in conversation: {len(result['messages'])}\")\n",
    "# print(\"\\n‚úÖ Agent can maintain context, use tools (when provided), and handle multi-turn!\")\n",
    "\n",
    "# Import official Valyu tool from langchain-valyu package\n",
    "from langchain_valyu import ValyuSearchTool\n",
    "\n",
    "# Create search tool with configuration\n",
    "search_tool = ValyuSearchTool(\n",
    "    valyu_api_key=os.getenv(\"VALYU_API_KEY\"),\n",
    "    # Optional: configure search parameters (can also be set per-call)\n",
    "    # search_type=\"all\",  # Search both proprietary and web sources\n",
    "    # max_num_results=5,   # Limit results\n",
    "    # relevance_threshold=0.5,  # Minimum relevance score\n",
    "    # max_price=20.0  # Maximum cost in dollars\n",
    ")\n",
    "\n",
    "# Test it directly\n",
    "print(\"üîç Testing Valyu Search Tool Directly\")\n",
    "print(\"=\" * 70)\n",
    "test_query = \"latest developments in quantum computing\"\n",
    "print(f\"Query: {test_query}\\n\")\n",
    "\n",
    "# Call the search tool\n",
    "search_results = search_tool._run(query=test_query, search_type=\"all\", max_num_results=5)\n",
    "\n",
    "# Display results (truncated for readability)\n",
    "result_str = str(search_results)\n",
    "print(\"üìÑ Search Results (first 500 chars):\")\n",
    "print(\"-\" * 70)\n",
    "print(result_str[:500] + \"...\" if len(result_str) > 500 else result_str)\n",
    "print(\"-\" * 70)\n",
    "print(f\"\\nüìä Total data returned: {len(result_str)} characters\")\n",
    "print(\"‚úÖ This data will be passed to the agent to answer questions!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "051183fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TEST 2: Agent WITH Search\n",
      "======================================================================\n",
      "\n",
      "‚ùì Same Question: What are the latest breakthroughs in quantum computing in 2025?\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gt/r39m3yss08l05rhcqrtkyys40000gn/T/ipykernel_1581/3187584785.py:30: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
      "  agent_with_search = create_react_agent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí¨ Response (WITH search):\n",
      "----------------------------------------------------------------------\n",
      "Based on the search results, I can provide a summary of the key quantum computing breakthroughs and developments in 2024-2025:\n",
      "\n",
      "Key Breakthroughs:\n",
      "\n",
      "1. Google's Willow Chip (Late 2024):\n",
      "- Achieved significant improvement in error correction and noise reduction\n",
      "- Demonstrated ability to perform computations that would take classical supercomputers extremely long periods to solve\n",
      "- Represents progress toward threshold scalability, though still not ready for practical applications\n",
      "\n",
      "2. Microsoft's Developments:\n",
      "- Unveiled the world's first quantum processor powered by topological qubits\n",
      "- Integrate...\n",
      "----------------------------------------------------------------------\n",
      "‚è±Ô∏è  Time: 55.61s\n",
      "\n",
      "‚úÖ Note: Real-time data, specific sources, up-to-date information!\n"
     ]
    }
   ],
   "source": [
    "# Test question about recent events (requires current information)\n",
    "recent_question = \"What are the latest breakthroughs in quantum computing in 2025?\"\n",
    "\n",
    "# print(\"=\"*70)\n",
    "# print(\"TEST 1: Agent WITHOUT Search\")\n",
    "# print(\"=\"*70)\n",
    "# print(f\"‚ùì Question: {recent_question}\\n\")\n",
    "\n",
    "# start_time = time.time()\n",
    "# result_no_search = agent.invoke({\n",
    "#     \"messages\": [HumanMessage(content=recent_question)]\n",
    "# })\n",
    "# elapsed_no_search = time.time() - start_time\n",
    "\n",
    "# print(\"üí¨ Response (NO search):\")\n",
    "# print(\"-\"*70)\n",
    "# response_text = result_no_search['messages'][-1].content\n",
    "# print(response_text[:400] + \"...\" if len(response_text) > 400 else response_text)\n",
    "# print(\"-\"*70)\n",
    "# print(f\"‚è±Ô∏è  Time: {elapsed_no_search:.2f}s\")\n",
    "# print(f\"\\n‚ö†Ô∏è  Note: Generic answer, likely outdated or vague (LLM training data cutoff)\")\n",
    "\n",
    "# Now create agent WITH search tool\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TEST 2: Agent WITH Search\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create new agent with Valyu search tool (uses Holistic AI Bedrock by default)\n",
    "llm_with_tools = get_chat_model(\"claude-3-5-sonnet\")\n",
    "agent_with_search = create_react_agent(\n",
    "    llm_with_tools,\n",
    "    tools=[search_tool],  # Add the search tool!\n",
    ")\n",
    "\n",
    "print(f\"\\n‚ùì Same Question: {recent_question}\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "result_with_search = agent_with_search.invoke({\"messages\": [HumanMessage(content=recent_question)]})\n",
    "elapsed_with_search = time.time() - start_time\n",
    "\n",
    "print(\"üí¨ Response (WITH search):\")\n",
    "print(\"-\" * 70)\n",
    "response_text = result_with_search[\"messages\"][-1].content\n",
    "print(response_text[:600] + \"...\" if len(response_text) > 600 else response_text)\n",
    "print(\"-\" * 70)\n",
    "print(f\"‚è±Ô∏è  Time: {elapsed_with_search:.2f}s\")\n",
    "print(\"\\n‚úÖ Note: Real-time data, specific sources, up-to-date information!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "506c143a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Message Trace (WITH search):\n",
      "======================================================================\n",
      "\n",
      "1. HumanMessage\n",
      "----------------------------------------------------------------------\n",
      "   User: What are the latest breakthroughs in quantum computing in 2025?...\n",
      "\n",
      "2. AIMessage\n",
      "----------------------------------------------------------------------\n",
      "   AI decided to call tool: valyu_deep_search\n",
      "   Args: {'query': 'major breakthroughs developments quantum computing 2025', 'start_date': '2025-01-01', 'end_date': '2025-12-31', 'max_num_results': 10}\n",
      "\n",
      "3. ToolMessage\n",
      "----------------------------------------------------------------------\n",
      "   Tool returned: {\n",
      "  \"success\": false,\n",
      "  \"error\": \"HTTP Error: 504\",\n",
      "  \"tx_id\": \"error-504\",\n",
      "  \"query\": \"major breakt...\n",
      "\n",
      "4. AIMessage\n",
      "----------------------------------------------------------------------\n",
      "   AI decided to call tool: valyu_deep_search\n",
      "   Args: {'query': 'latest breakthroughs developments quantum computing 2024', 'max_num_results': 10}\n",
      "\n",
      "5. ToolMessage\n",
      "----------------------------------------------------------------------\n",
      "   Tool returned: {\n",
      "  \"success\": true,\n",
      "  \"error\": \"\",\n",
      "  \"tx_id\": \"tx_4ad7df01-9c40-4370-9939-f2b6b5f50cc7\",\n",
      "  \"query\":...\n",
      "\n",
      "6. AIMessage\n",
      "----------------------------------------------------------------------\n",
      "   AI response: Based on the search results, I can provide a summary of the key quantum computing breakthroughs and developments in 2024-2025:\n",
      "\n",
      "Key Breakthroughs:\n",
      "\n",
      "1....\n",
      "\n",
      "======================================================================\n",
      "Total messages: 6\n",
      "\n",
      "This shows the complete ReAct loop: User ‚Üí AI (tool call) ‚Üí Tool ‚Üí AI (answer)\n"
     ]
    }
   ],
   "source": [
    "print(\"üìä Message Trace (WITH search):\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, msg in enumerate(result_with_search[\"messages\"]):\n",
    "    msg_type = type(msg).__name__\n",
    "    print(f\"\\n{i + 1}. {msg_type}\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "    if msg_type == \"HumanMessage\":\n",
    "        print(f\"   User: {msg.content[:100]}...\")\n",
    "\n",
    "    elif msg_type == \"AIMessage\":\n",
    "        if hasattr(msg, \"tool_calls\") and msg.tool_calls:\n",
    "            print(f\"   AI decided to call tool: {msg.tool_calls[0]['name']}\")\n",
    "            print(f\"   Args: {msg.tool_calls[0]['args']}\")\n",
    "        else:\n",
    "            content_preview = msg.content[:150] + \"...\" if len(msg.content) > 150 else msg.content\n",
    "            print(f\"   AI response: {content_preview}\")\n",
    "\n",
    "    elif msg_type == \"ToolMessage\":\n",
    "        content_preview = msg.content[:100] + \"...\" if len(msg.content) > 100 else msg.content\n",
    "        print(f\"   Tool returned: {content_preview}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"Total messages: {len(result_with_search['messages'])}\")\n",
    "print(\"\\nThis shows the complete ReAct loop: User ‚Üí AI (tool call) ‚Üí Tool ‚Üí AI (answer)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ede93dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema defined!\n",
      "   Fields: ['entities']\n",
      "   Entity Fields: ['name', 'tone', 'evidence_sentences', 'loaded_phrases']\n",
      "   Validation: Built-in with Pydantic\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "\n",
    "# Define output schema\n",
    "class Entity(BaseModel):\n",
    "    \"\"\"Person, group, or institution mentioned in the article. Contains information and evidence about bias presented.\"\"\"\n",
    "\n",
    "    name: str = Field(description=\"Name of person, group, institution, or organization mentioned\")\n",
    "    tone: str = Field(\n",
    "        description=\"Sentiment within the article towards the entity mentioned: MUST be one of the following: 'very positive', 'positive', 'neutral', 'negative', 'very negative'\"\n",
    "    )\n",
    "    evidence_sentences: List[str] = Field(\n",
    "        description=\"Phrases or sentences pulled directly from the provided article that demonstrate the sentiment of the article toward this entity\"\n",
    "    )\n",
    "    loaded_phrases: List[str] = Field(\n",
    "        description=\"Emotionally charged or manipulative wording or phrases used in the article pertaining to the entity\"\n",
    "    )\n",
    "\n",
    "\n",
    "class EntityAnalysis(BaseModel):\n",
    "    \"\"\"Analysis of the entities discussed in the article and how the sentiment presented toward them.\"\"\"\n",
    "\n",
    "    entities: List[Entity] = Field(description=\"All of the people, groups, or institutions mentioned in the article.\")\n",
    "\n",
    "\n",
    "print(\"Schema defined!\")\n",
    "print(f\"   Fields: {list(EntityAnalysis.model_fields.keys())}\")\n",
    "print(f\"   Entity Fields: {list(Entity.model_fields.keys())}\")\n",
    "print(\"   Validation: Built-in with Pydantic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0b6eca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LLM with structured output created!\n",
      "   Model: claude-3-5-sonnet (via Bedrock)\n",
      "   Output format: TechAnalysis (JSON)\n",
      "   Validation: Automatic with Pydantic\n"
     ]
    }
   ],
   "source": [
    "# Create base LLM\n",
    "# Use get_chat_model() - uses Holistic AI Bedrock by default (recommended)\n",
    "llm = get_chat_model(\"claude-3-5-sonnet\")  # Uses Holistic AI Bedrock (recommended)\n",
    "\n",
    "# Create LLM with structured output\n",
    "llm_structured = llm.with_structured_output(EntityAnalysis)\n",
    "print(\"‚úÖ LLM with structured output created!\")\n",
    "print(\"   Model: claude-3-5-sonnet (via Bedrock)\")\n",
    "print(\"   Output format: TechAnalysis (JSON)\")\n",
    "print(\"   Validation: Automatic with Pydantic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e3020cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: You are an entity-level bias detector.\n",
      "\n",
      "Identify all people, groups, or institutions discussed in the article.\n",
      "For each entity, determine the tone:\n",
      "'very_positive', 'positive', 'neutral', 'negative', 'very_negative'\n",
      "\n",
      "Extract:\n",
      "- 1‚Äì3 evidence sentences that reflect this tone\n",
      "- any \"loaded phrases\" (emotionally charged or manipulative wording)\n",
      "\n",
      "Article:\n",
      "\"More than 300 people gathered in Bournemouth earlier as a planned immigration protest took place.\n",
      "The march, organised by Bournemouth Patriots, with a \"stop the boats\" message, followed a pre-agreed route along Meyrick Road to a designated location near the Lansdowne.\n",
      "\n",
      "Counter protesters and supporters of Stand up to Racism were also present, with many chanting \"refugees are welcome here\".\n",
      "\n",
      "Dorset Police said it respected people's right to peaceful protest, but were \"imposing conditions for safety\" and to \"minimise disruption\".\n",
      "\n",
      "BBC reporter Steve Humphrey said about 300 people gathered at the height of the protest, with equal numbers from both sides.\n",
      "\n",
      "He said some were chanting, while waving Union Jack and England flags.\n",
      "\n",
      "It was the latest in a series of protests in the town, with police warning demonstrators would be committing an offence if they failed to follow official instructions.\n",
      "\n",
      "The Bournemouth Patriots turned down an invitation to be interviewed by the BBC and said the corporation was not welcome at the event.\"\n",
      "\n",
      "======================================================================\n",
      "Structured Output (Pydantic Object):\n",
      "======================================================================\n",
      "  1. name='Bournemouth Patriots' tone='negative' evidence_sentences=[\"The march, organised by Bournemouth Patriots, with a 'stop the boats' message, followed a pre-agreed route along Meyrick Road\", 'The Bournemouth Patriots turned down an invitation to be interviewed by the BBC and said the corporation was not welcome at the event'] loaded_phrases=['stop the boats']\n",
      "  2. name='Stand up to Racism' tone='positive' evidence_sentences=[\"Counter protesters and supporters of Stand up to Racism were also present, with many chanting 'refugees are welcome here'\"] loaded_phrases=['refugees are welcome here']\n",
      "  3. name='Dorset Police' tone='neutral' evidence_sentences=[\"Dorset Police said it respected people's right to peaceful protest, but were 'imposing conditions for safety' and to 'minimise disruption'\", 'It was the latest in a series of protests in the town, with police warning demonstrators would be committing an offence if they failed to follow official instructions'] loaded_phrases=[]\n",
      "  4. name='BBC' tone='neutral' evidence_sentences=['BBC reporter Steve Humphrey said about 300 people gathered at the height of the protest, with equal numbers from both sides', 'The Bournemouth Patriots turned down an invitation to be interviewed by the BBC and said the corporation was not welcome at the event'] loaded_phrases=[]\n",
      "  5. name='Steve Humphrey' tone='neutral' evidence_sentences=['BBC reporter Steve Humphrey said about 300 people gathered at the height of the protest, with equal numbers from both sides'] loaded_phrases=[]\n",
      "======================================================================\n",
      "Time: 8.22s\n"
     ]
    }
   ],
   "source": [
    "# Test structured output\n",
    "question = 'You are an entity-level bias detector.\\n\\nIdentify all people, groups, or institutions discussed in the article.\\nFor each entity, determine the tone:\\n\\'very_positive\\', \\'positive\\', \\'neutral\\', \\'negative\\', \\'very_negative\\'\\n\\nExtract:\\n- 1‚Äì3 evidence sentences that reflect this tone\\n- any \"loaded phrases\" (emotionally charged or manipulative wording)\\n\\nArticle:\\n\"More than 300 people gathered in Bournemouth earlier as a planned immigration protest took place.\\nThe march, organised by Bournemouth Patriots, with a \"stop the boats\" message, followed a pre-agreed route along Meyrick Road to a designated location near the Lansdowne.\\n\\nCounter protesters and supporters of Stand up to Racism were also present, with many chanting \"refugees are welcome here\".\\n\\nDorset Police said it respected people\\'s right to peaceful protest, but were \"imposing conditions for safety\" and to \"minimise disruption\".\\n\\nBBC reporter Steve Humphrey said about 300 people gathered at the height of the protest, with equal numbers from both sides.\\n\\nHe said some were chanting, while waving Union Jack and England flags.\\n\\nIt was the latest in a series of protests in the town, with police warning demonstrators would be committing an offence if they failed to follow official instructions.\\n\\nThe Bournemouth Patriots turned down an invitation to be interviewed by the BBC and said the corporation was not welcome at the event.\"'\n",
    "\n",
    "# question = \"You are an entity-level bias detector.\\n\\nIdentify all people, groups, or institutions discussed in the article.\\nFor each entity, determine the tone:\\n'very_positive', 'positive', 'neutral', 'negative', 'very_negative'\\n\\nExtract:\\n- 1‚Äì3 evidence sentences that reflect this tone\\n- any \\\"loaded phrases\\\" (emotionally charged or manipulative wording)\\n\\nArticle:\\n\\\"The Strategic Uncoupling of Zohran Mamdani and Brad Lander\\n\\nMr. Lander, the New York City comptroller, campaigned with Mr. Mamdani and once hoped to join him in City Hall. Now he is eyeing a congressional seat. Zohran Mamdani was in the final, chaotic sprint to Election Day in the New York City mayor‚Äôs race, when he stepped off the campaign trail for an important meeting.\\n\\nSitting with him was Brad Lander, the city comptroller who had become one of his closest allies. Their \\‚Äúprogressive bromance\\‚Äù during the Democratic primary in June had helped cinch Mr. Mamdani\\‚Äôs victory and left Mr. Lander gunning for City Hall, too, hopefully as his top deputy.\\n\\nBut when they met on a chaotic Sunday in late October, amid church services and canvass launches, Mr. Mamdani, a state assemblyman, wanted to talk about a different idea that Mr. Lander had floated. He told the comptroller that he would like to continue their partnership ‚Äî by supporting him in a primary challenge against Representative Daniel Goldman, a vulnerable and more moderate Democrat, according to three people familiar with the exchange.\\n\\nAs for the high-level administration post Mr. Lander, 56, had also coveted, Mr. Mamdani told him that he planned to go in a different direction.The sharp change-up has captivated New York‚Äôs political chattering class since it spilled into public in recent days, setting the stage for a potentially explosive House primary in the heart of New York City.\\n\\nMr. Mamdani\\‚Äôs quiet maneuvering ‚Äî much of which has not been previously reported ‚Äî has also offered an early window into the unsentimental calculations guiding the incoming mayor as he builds his administration and flexes his political muscle.\\n\\nAsked to comment for this story, Mr. Mamdani‚Äôs spokeswoman, Dora Pekec, said simply that Mr. Lander ‚Äúcontinues to be a trusted ally and partner to the mayor-elect.‚Äù But other supporters who have spoken to him added that Mr. Mamdani, a sharp critic of Israel, was eager to unseat Mr. Goldman, whose views on the war in Gaza and other issues are well to his right.\\n\\nPeople who have spoken with Mr. Lander recently said he had played down the sting of being passed over for a top city post.\\n\\n\\‚ÄúBrad\\‚Äôs moral clarity, his willingness to use his voice to defend our democracy and put his body on the line to protect our neighbors are all vitally important and unfortunately all too rare,‚Äù said his top adviser, Alison Hirsh. She said he would bring these qualities to Washington ‚Äúif he chooses to run.‚Äù\\n\\nThe relationship between Mr. Lander and Mr. Mamdani has been the subject of unusual interest since the two men rolled out a novel cross-endorsement in June as competing candidates for mayor. Politicians often talk about forming alliances to defeat a common enemy, in this case former Gov. Andrew M. Cuomo, but rarely follow through.Mr. Lander, a well-known progressive with 15 years in public office, vouched for Mr. Mamdani, a 34-year-old Muslim and democratic socialist, with fellow Jewish Democrats. And after federal agents arrested Mr. Lander as he escorted migrants in an immigration courthouse, he used some of the attention to boost his formal rival.\\n\\nOn the night of his primary victory, Mr. Mamdani put his arm around Mr. Lander and said they had modeled \\‚Äúthe politics of the future, one of partnership and of sincerity.\\‚Äù\\n\\nMany progressive New Yorkers supporting Mr. Mamdani ‚Äî but uncertain about his youth with just five years in the State Assembly under his belt ‚Äî felt comforted by the prospect of Mr. Lander joining City Hall as a partner overseeing the city‚Äôs day-to-day operations.\\\"\"\n",
    "\n",
    "print(f\"Question: {question}\\n\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "start_time = time.time()\n",
    "result = llm_structured.invoke(question)\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(\"Structured Output (Pydantic Object):\")\n",
    "print(\"=\" * 70)\n",
    "for i, entity in enumerate(result.entities, 1):\n",
    "    print(f\"  {i}. {entity}\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"Time: {elapsed:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40406c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Scraping and analyzing articles...\n",
      "\n",
      "‚úÖ Successfully processed 1 articles.\n",
      "\n",
      "--- ARTICLE 1 ---\n",
      "üì∞ Title:   Anti-migrant protest dwarfed by counter demonstration in Bristol\n",
      "üîó URL:     https://www.bbc.co.uk/news/articles/c5yle7nepd5o?utm_source=valyu.ai&utm_medium=referral\n",
      "\n",
      "ü§ñ AI Analysis (Valyu):\n",
      "Here is a structured bias detection analysis of the provided article, tailored for downstream AI applications:\n",
      "\n",
      "---\n",
      "\n",
      "### **1. MAIN THESIS**  \n",
      "The article reports on a protest and counter-protest in Bristol over immigration, highlighting the presence of both anti-migrant demonstrators and counter-demonstrators, with police ensuring peaceful assembly.\n",
      "\n",
      "---\n",
      "\n",
      "### **2. FRAMING**  \n",
      "**Lean: Center**  \n",
      "**Evidence:**  \n",
      "- The article presents both sides of the protest (anti-immigration group and counter-protesters) without overtly endorsing one side over the other.  \n",
      "- The tone is factual and neutral, with a focus on the number of participants, police response, and public safety.  \n",
      "- Quotes from police (e.g., Ch Insp Keith Smith) emphasize impartiality and the protection of peaceful protest.  \n",
      "- No overt ideological slant is present in the reporting style or word choice.\n",
      "\n",
      "---\n",
      "\n",
      "### **3. RHETORIC ALERTS**  \n",
      "**Loaded Language / Euphemisms / Dog Whistles Identified:**  \n",
      "- **\"Anti-migrant protesters\"** ‚Äì This term is neutral in tone but carries connotation in political discourse. It is not inherently biased but can be used to signal anti-immigrant sentiment.  \n",
      "- **\"Defend the Mercure\"** ‚Äì A call to action from counter-protesters. While not explicitly biased, the phrase implies a moral or protective stance toward housing refugees, which can be a left-leaning framing.  \n",
      "- **\"Bristol Patriots\"** ‚Äì A name that may act as a dog-whistle in political discourse, often associated with right-leaning or nationalist groups. However, in this context, it is used as a group‚Äôs self-identification, not by the article.  \n",
      "- **\"Hate, discrimination or violence\"** ‚Äì A broad condemnation used by police, which is standard but not inherently biased.\n",
      "\n",
      "---\n",
      "\n",
      "### **4. MANIPULATION CHECK**  \n",
      "**Us vs. Them Language or Fear-Mongering Detected:**  \n",
      "- **Us vs. Them:**  \n",
      "  - The article does not explicitly use \"us vs. them\" language. However, the framing of two opposing groups (anti-migrant protesters vs. counter-protesters) inherently sets up a binary.  \n",
      "  - The term \"Bristol Patriots\" may imply an in-group identity, but this is not emphasized by the article.  \n",
      "- **Fear-Mongering:**  \n",
      "  - There is no explicit fear-mongering in the article.  \n",
      "  - The police statement about not tolerating \"hate, discrimination or violence\" is a standard public reassurance and not manipulative.  \n",
      "  - The mention of \"clashing with police\" is factual and does not exaggerate threat or danger.\n",
      "\n",
      "---\n",
      "\n",
      "### **Summary for AI Applications**  \n",
      "This article is **neutral in tone** and **center-leaning in framing**, providing balanced coverage of a protest and counter-protest event in Bristol. It avoids overtly biased language and does not engage in fear-mongering or divisive rhetoric. Key rhetorical elements like \"Bristol Patriots\" and \"Defend the Mercure\" are present but used descriptively, not to influence reader perception. The article is suitable as a neutral baseline for training AI systems in bias detection, particularly for identifying implicit framing and loaded terms in protest-related reporting.\n",
      "\n",
      "--- \n",
      "\n",
      "Let me know if you‚Äôd like this structured in JSON or another format for integration into an AI system.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# not this bc we need it to be explainable\n",
    "from valyu import Valyu\n",
    "import os\n",
    "\n",
    "# # Initialize Valyu (it will auto-read VALYU_API_KEY from your environment)\n",
    "# # If you haven't set it in .env yet, uncomment the line below:\n",
    "# # valyu = Valyu(api_key=\"YOUR_KEY_HERE\")\n",
    "valyu = Valyu() \n",
    "\n",
    "# 1. Define your \"Bias Detector\" prompt for the ingestion engine\n",
    "# We instruct Valyu to structure the summary exactly how your app needs it.\n",
    "bias_analysis_prompt = \"\"\"\n",
    "Analyze this article for a bias detection application. Provide a structured summary with these sections:\n",
    "1. MAIN THESIS: The core claim or argument (1 sentence).\n",
    "2. FRAMING: Is this Left, Right, or Center leaning? What is the evidence?\n",
    "3. RHETORIC ALERTS: List any loaded language, dog-whistles, or euphemisms found.\n",
    "4. MANIPULATION CHECK: Is there 'us vs them' language or fear-mongering?\n",
    "\"\"\"\n",
    "\n",
    "print(\"‚è≥ Scraping and analyzing articles...\")\n",
    "\n",
    "# 2. Call Valyu to Scrape + Summarize\n",
    "response = valyu.contents(\n",
    "    urls=[\n",
    "        \"https://www.nytimes.com/2025/11/14/nyregion/mamdani-lander-dan-goldman.html\",\n",
    "        \"https://www.bbc.co.uk/news/articles/c5yle7nepd5o\"\n",
    "    ],\n",
    "    summary=bias_analysis_prompt,  # Pass our custom prompt here\n",
    "    extract_effort=\"high\",\n",
    "    response_length=\"max\"\n",
    ")\n",
    "\n",
    "# 3. Process and Print Results\n",
    "print(f\"\\n‚úÖ Successfully processed {len(response.results)} articles.\\n\")\n",
    "\n",
    "for i, result in enumerate(response.results, 1):\n",
    "    print(f\"--- ARTICLE {i} ---\")\n",
    "    print(f\"üì∞ Title:   {result.title}\")\n",
    "    print(f\"üîó URL:     {result.url}\")\n",
    "    \n",
    "    # CRITICAL CHANGE: We access .summary for the analysis, .content for the raw text\n",
    "    print(f\"\\nü§ñ AI Analysis (Valyu):\")\n",
    "    print(result.summary) \n",
    "    \n",
    "    # Optional: Store the raw content if you want your Claude agent to re-read it later\n",
    "    # full_text = result.content \n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903a5969",
   "metadata": {},
   "outputs": [],
   "source": [
    "from valyu import Valyu\n",
    "\n",
    "# Initialize\n",
    "valyu = Valyu() # picks up API key from env\n",
    "\n",
    "print(\"‚è≥ Fetching article contents...\")\n",
    "\n",
    "response = valyu.contents(\n",
    "    urls=[\"https://www.bbc.co.uk/news/articles/c5yle7nepd5o\"],\n",
    "    # Basic summary only - we need do the analysis ourselves for explainability\n",
    "    summary=\"Provide a neutral, 3-bullet summary of the article.\", \n",
    "    extract_effort=\"auto\"\n",
    ")\n",
    "\n",
    "# We will grab the full text of the first result for the deep analysis\n",
    "article_text = response.results[0].content\n",
    "article_title = response.results[0].title\n",
    "\n",
    "print(f\"‚úÖ Loaded: {article_title}\")\n",
    "print(f\"üìù Sample text: {article_text[:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2e6842",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal, List\n",
    "\n",
    "# 1. Define the Schema for Explainability\n",
    "class Statement(BaseModel):\n",
    "    text: str = Field(description=\"The exact sentence or clause from the text\")\n",
    "    type: Literal[\"objective\", \"subjective\"] = Field(description=\"'objective' if factual/verifiable, 'subjective' if opinion/emotional/interpretation\")\n",
    "    reasoning: str = Field(description=\"Brief explanation of why this classification was chosen\")\n",
    "\n",
    "class ContentAnalysis(BaseModel):\n",
    "    statements: List[Statement]\n",
    "\n",
    "# 2. Setup the LLM (using your existing Bedrock/Claude setup)\n",
    "llm_classifier = llm.with_structured_output(ContentAnalysis)\n",
    "\n",
    "# 3. The Analysis Function\n",
    "def analyze_objectivity(text_content):\n",
    "    prompt = f\"\"\"\n",
    "    You are a fact-checking engine. Break the following news text into individual statements.\n",
    "    Classify each statement as 'objective' (facts, quotes, verifiable events) or 'subjective' (opinions, framing, emotional language).\n",
    "    \n",
    "    Text to analyze:\n",
    "    \"{text_content[:4000]}\" \n",
    "    \"\"\"\n",
    "    # Note: Sliced to 4000 chars to save tokens for this demo, remove slice for full article\n",
    "    \n",
    "    return llm_classifier.invoke(prompt)\n",
    "\n",
    "# 4. Run Analysis\n",
    "print(\"‚è≥ Analyzing statements (this ensures explainability)...\")\n",
    "analysis_result = analyze_objectivity(article_text)\n",
    "\n",
    "# 5. Calculate the Metrics in Python (The \"Glass Box\" Math)\n",
    "total_statements = len(analysis_result.statements)\n",
    "objective_count = sum(1 for s in analysis_result.statements if s.type == 'objective')\n",
    "subjective_count = sum(1 for s in analysis_result.statements if s.type == 'subjective')\n",
    "\n",
    "obj_score = (objective_count / total_statements) * 100 if total_statements > 0 else 0\n",
    "subj_score = (subjective_count / total_statements) * 100 if total_statements > 0 else 0\n",
    "\n",
    "# 6. Output Results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"üìä OBJECTIVITY SCORE: {obj_score:.1f}%\")\n",
    "print(f\"üé≠ SUBJECTIVITY SCORE: {subj_score:.1f}%\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Show the \"Proof\" (Explainability)\n",
    "print(\"\\nüîç EXPLAINABILITY LOG (First 5 statements):\")\n",
    "for item in analysis_result.statements[:5]:\n",
    "    icon = \"‚úÖ\" if item.type == \"objective\" else \"‚ö†Ô∏è\"\n",
    "    print(f\"{icon} [{item.type.upper()}] {item.text}\")\n",
    "    print(f\"   User Reason: {item.reasoning}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biassphere (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
